{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environment variables\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"mental-heath-in-tech-2016_20161114.csv\")\n",
    "df_work = df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datatypes\n",
    "df_work.dtypes.to_frame().groupby(0).size().to_frame().rename(columns={0:'count'}).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['self-employed', 'num_employees', 'tech_comp', 'tech_role',\n",
       "       'emp_benefits', 'emp_know_options', 'emp_discussed', 'emp_ressources',\n",
       "       'emp_anonymity', 'emp_medicalleave', 'emp_disc_mhdisorder_negcons',\n",
       "       'emp_disc_mhissue_negcons', 'emp_disc_mhdisorder_coworkers',\n",
       "       'emp_disc_mhdisorder_supervisor', 'emp_mh_ph_serious',\n",
       "       'emp_observed_negcons', 'se_coverage_mh', 'se_ressources',\n",
       "       'se_reveal_clients', 'se_reveal_clients_negcons', 'se_reveal_coworkers',\n",
       "       'se_reveal_coworkers_negcons', 'productivity_affected',\n",
       "       'productivity_affected_percentage', 'prev_emp', 'prevemp_benefits',\n",
       "       'prevemp_know_options', 'prevemp_discussed', 'prevemp_ressources',\n",
       "       'prevemp_anonymity', 'prevemp_mh_disc_negcons',\n",
       "       'prevemp_ph_disc_negcons', 'prevemp_disc_mhissues_coworkers',\n",
       "       'prevemp_disc_mhissues_supervisor', 'prevemp_mh_ph_serious',\n",
       "       'prevemp_negcons', 'ph_jobinterview', 'why', 'mh_jobinterview', 'why.1',\n",
       "       'mh_career', 'mh_coworkers_perspective_neg', 'mh_sharewfriends',\n",
       "       'mhi_badresponse_work',\n",
       "       'observations_otherindividual_less_likely_reveal', 'family_history',\n",
       "       'mhdisorder_past', 'mhdisorder_now', 'mhdisorder_what_diagnosed',\n",
       "       'mhdisorder_what_believe', 'mh_diagnosed_medprof',\n",
       "       'medprof_what_diagnosed', 'sought_treatment',\n",
       "       'mhi_treated_inferencework', 'mhi_NOTtreated_inferencework', 'age',\n",
       "       'gender', 'country_live', 'usstate_live', 'country_work',\n",
       "       'usstate_work', 'work_position', 'remotework'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns\n",
    "\n",
    "li_or_col = list(df_work.columns)\n",
    "\n",
    "di_col = {\n",
    "'Are you self-employed?':'self-employed',\n",
    "'How many employees does your company or organization have?':'num_employees',\n",
    "'Is your employer primarily a tech company/organization?':'tech_comp',\n",
    "'Is your primary role within your company related to tech/IT?':'tech_role',\n",
    "'Does your employer provide mental health benefits as part of healthcare coverage?':'emp_benefits',\n",
    "'Do you know the options for mental health care available under your employer-provided coverage?':'emp_know_options',\n",
    "'Has your employer ever formally discussed mental health (for example, as part of a wellness campaign or other official communication)?':'emp_discussed',\n",
    "'Does your employer offer resources to learn more about mental health concerns and options for seeking help?':'emp_ressources',\n",
    "'Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer?':'emp_anonymity',\n",
    "'If a mental health issue prompted you to request a medical leave from work, asking for that leave would be:':'emp_medicalleave',\n",
    "'Do you think that discussing a mental health disorder with your employer would have negative consequences?':'emp_disc_mhdisorder_negcons',\n",
    "'Do you think that discussing a physical health issue with your employer would have negative consequences?':'emp_disc_mhissue_negcons',\n",
    "'Would you feel comfortable discussing a mental health disorder with your coworkers?':'emp_disc_mhdisorder_coworkers',\n",
    "'Would you feel comfortable discussing a mental health disorder with your direct supervisor(s)?':'emp_disc_mhdisorder_supervisor',\n",
    "'Do you feel that your employer takes mental health as seriously as physical health?':'emp_mh_ph_serious',\n",
    "'Have you heard of or observed negative consequences for co-workers who have been open about mental health issues in your workplace?':'emp_observed_negcons',\n",
    "'Do you have medical coverage (private insurance or state-provided) which includes treatment of mental health issues?':'se_coverage_mh',\n",
    "'Do you know local or online resources to seek help for a mental health disorder?':'se_ressources',\n",
    "'If you have been diagnosed or treated for a mental health disorder, do you ever reveal this to clients or business contacts?':'se_reveal_clients',\n",
    "'If you have revealed a mental health issue to a client or business contact, do you believe this has impacted you negatively?':'se_reveal_clients_negcons',\n",
    "'If you have been diagnosed or treated for a mental health disorder, do you ever reveal this to coworkers or employees?':'se_reveal_coworkers',\n",
    "'If you have revealed a mental health issue to a coworker or employee, do you believe this has impacted you negatively?':'se_reveal_coworkers_negcons',\n",
    "'Do you believe your productivity is ever affected by a mental health issue?':'productivity_affected',\n",
    "'If yes, what percentage of your work time (time performing primary or secondary job functions) is affected by a mental health issue?':'productivity_affected_percentage',\n",
    "'Do you have previous employers?':'prev_emp',\n",
    "'Have your previous employers provided mental health benefits?':'prevemp_benefits',\n",
    "'Were you aware of the options for mental health care provided by your previous employers?':'prevemp_know_options',\n",
    "'Did your previous employers ever formally discuss mental health (as part of a wellness campaign or other official communication)?':'prevemp_discussed',\n",
    "'Did your previous employers provide resources to learn more about mental health issues and how to seek help?':'prevemp_ressources',\n",
    "'Was your anonymity protected if you chose to take advantage of mental health or substance abuse treatment resources with previous employers?':'prevemp_anonymity',\n",
    "'Do you think that discussing a mental health disorder with previous employers would have negative consequences?':'prevemp_mh_disc_negcons',\n",
    "'Do you think that discussing a physical health issue with previous employers would have negative consequences?':'prevemp_ph_disc_negcons',\n",
    "'Would you have been willing to discuss a mental health issue with your previous co-workers?':'prevemp_disc_mhissues_coworkers',\n",
    "'Would you have been willing to discuss a mental health issue with your direct supervisor(s)?':'prevemp_disc_mhissues_supervisor',\n",
    "'Did you feel that your previous employers took mental health as seriously as physical health?':'prevemp_mh_ph_serious',\n",
    "'Did you hear of or observe negative consequences for co-workers with mental health issues in your previous workplaces?':'prevemp_negcons',\n",
    "'Would you be willing to bring up a physical health issue with a potential employer in an interview?':'ph_jobinterview',\n",
    "'Why or why not?':'why',\n",
    "'Would you bring up a mental health issue with a potential employer in an interview?':'mh_jobinterview',\n",
    "'Why or why not?.1':'why.1',\n",
    "'Do you feel that being identified as a person with a mental health issue would hurt your career?':'mh_career',\n",
    "'Do you think that team members/co-workers would view you more negatively if they knew you suffered from a mental health issue?':'mh_coworkers_perspective_neg',\n",
    "'How willing would you be to share with friends and family that you have a mental illness?':'mh_sharewfriends',\n",
    "'Have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?':'mhi_badresponse_work',\n",
    "'Have your observations of how another individual who discussed a mental health disorder made you less likely to reveal a mental health issue yourself in your current workplace?':'observations_otherindividual_less_likely_reveal',\n",
    "'Do you have a family history of mental illness?':'family_history',\n",
    "'Have you had a mental health disorder in the past?':'mhdisorder_past',\n",
    "'Do you currently have a mental health disorder?':'mhdisorder_now',\n",
    "'If yes, what condition(s) have you been diagnosed with?':'mhdisorder_what_diagnosed',\n",
    "'If maybe, what condition(s) do you believe you have?':'mhdisorder_what_believe',\n",
    "'Have you been diagnosed with a mental health condition by a medical professional?':'mh_diagnosed_medprof',\n",
    "'If so, what condition(s) were you diagnosed with?':'medprof_what_diagnosed',\n",
    "'Have you ever sought treatment for a mental health issue from a mental health professional?':'sought_treatment',\n",
    "'If you have a mental health issue, do you feel that it interferes with your work when being treated effectively?':'mhi_treated_inferencework',\n",
    "'If you have a mental health issue, do you feel that it interferes with your work when NOT being treated effectively?':'mhi_NOTtreated_inferencework',\n",
    "'What is your age?':'age',\n",
    "'What is your gender?':'gender',\n",
    "'What country do you live in?':'country_live',\n",
    "'What US state or territory do you live in?':'usstate_live',\n",
    "'What country do you work in?':'country_work',\n",
    "'What US state or territory do you work in?':'usstate_work',\n",
    "'Which of the following best describes your work position?':'work_position',\n",
    "'Do you work remotely?':'remotework'\n",
    "}\n",
    "\n",
    "df_work.rename(columns=di_col, inplace=True)\n",
    "df_work.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us start with some exploration of the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_work.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some exploration\n",
    "print(df_work.head())\n",
    "print(df_work.describe())\n",
    "print(df_work.describe(include=['O']))\n",
    "print(df_work.columns)\n",
    "print(df_work.dtypes)\n",
    "print(df_work.dtypes.to_frame().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring nan values\n",
    "print(df_work.isnull().sum())\n",
    "print(df_work.isnull().sum().sum())\n",
    "print(df_work.isnull().sum().sum()/df_work.size*100,'%')\n",
    "\n",
    "li_percentages = []\n",
    "\n",
    "for col in df_work.columns:\n",
    "    print(col, ':', df_work[col].isnull().sum(), ':', df_work[col].isnull().sum()/df_work[col].size*100,'%')\n",
    "    li_percentages.append(df_work[col].isnull().sum()/df_work[col].size*100)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the percentages\n",
    "li_percentages_bins = pd.cut(li_percentages, bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "\n",
    "ax = li_percentages_bins.value_counts().plot.bar(rot=0, color=\"b\", figsize=(6,4))\n",
    "plt.title('Percentage of NaN values per column')\n",
    "plt.xlabel('Percentage of NaN values')\n",
    "plt.ylabel('Number of columns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns with value counts including nan values\n",
    "for col in df_work.columns:\n",
    "    print(col)\n",
    "    print(df_work[col].value_counts(dropna=False))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list columns with more than 80% of nan values\n",
    "for col in df_work.columns:\n",
    "    if df_work[col].isnull().sum()/df_work[col].size*100 > 80:\n",
    "        print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value count on the whole dataframe\n",
    "print(df_work.nunique(dropna=False).sum())\n",
    "\n",
    "df_work.nunique(dropna=False).to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploratory plots of emp-fields\n",
    "for col in df_work.columns:\n",
    "    if col.startswith('emp_'):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.countplot(x=col, data=df_work)\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploratory plots of se-fields\n",
    "for col in df_work.columns:\n",
    "    if col.startswith('se_'):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.countplot(x=col, data=df_work)\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploratory plots of prevemp-fields\n",
    "for col in df_work.columns:\n",
    "    if col.startswith('prev'):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.countplot(x=col, data=df_work)\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_work['mhdisorder_now'].value_counts(normalize=True))\n",
    "print(df_work['mhdisorder_past'].value_counts(normalize=True))\n",
    "\n",
    "#plot mhdisorder_now and mhdisorder_past\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "sns.countplot(x='mhdisorder_now', data=df_work, ax=ax[0])\n",
    "sns.countplot(x='mhdisorder_past', data=df_work, ax=ax[1])\n",
    "plt.savefig('mhdisorder_now_past.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare top 5 countries work and live with most respondents\n",
    "print('Country live')\n",
    "print(df_work['country_live'].value_counts().head(5))\n",
    "print(' ')\n",
    "print('Country work')\n",
    "print(df_work['country_work'].value_counts().head(5))\n",
    "\n",
    "# plot top 5 countries live against countries work in grouped bar chart\n",
    "df_work['country_live'].value_counts().head(5).plot(kind='bar', color='blue', alpha=0.5, label='live')\n",
    "df_work['country_work'].value_counts().head(5).plot(kind='bar', color='green', alpha=0.5, label='work')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Top 5 countries live vs work')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After some exploratory analysis, we will now start to clean the columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we are investigating regarding empolyees, we will drop all rows where self-employed is yes\n",
    "print(df_work.shape)\n",
    "df_work = df_work.loc[df_work['self-employed'] == 0]\n",
    "df_work.drop(columns=['self-employed'], inplace=True)\n",
    "print(df_work.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect columns with more than 70% of nan values and drop these columns\n",
    "for col in df_work.columns:\n",
    "    if df_work[col].isnull().sum()/df_work[col].size*100 > 70:\n",
    "        print(col)\n",
    "        df_work.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if variables are dependent, so one can be removed \n",
    "li_test_pairs = [\n",
    "                [\"country_live\",\"country_work\"],\n",
    "                [\"usstate_live\",\"usstate_work\"],\n",
    "                [\"medprof_what_diagnosed\",\"mhdisorder_what_diagnosed\"],\n",
    "                [\"medprof_what_diagnosed\",\"mh_diagnosed_medprof\"],\n",
    "                [\"emp_disc_mhdisorder_negcons\",\"emp_disc_mhissue_negcons\"],\n",
    "                [\"emp_disc_mhdisorder_coworkers\",\"emp_disc_mhissue_negcons\"],\n",
    "                [\"emp_disc_mhdisorder_supervisor\",\"emp_disc_mhissue_negcons\"],\n",
    "                [\"emp_observed_negcons\",\"emp_disc_mhissue_negcons\"],\n",
    "                [\"prevemp_ph_disc_negcons\",\"prevemp_mh_disc_negcons\"],\n",
    "                [\"prevemp_disc_mhissues_coworkers\",\"prevemp_mh_disc_negcons\"],\n",
    "                [\"prevemp_disc_mhissues_supervisor\",\"prevemp_mh_disc_negcons\"],\n",
    "                [\"prevemp_negcons\",\"prevemp_mh_disc_negcons\"],\n",
    "                [\"ph_jobinterview\",\"mh_jobinterview\"],\n",
    "                [\"mh_career\",\"mh_coworkers_perspective_neg\"],\n",
    "                [\"mh_career\",\"mh_sharewfriends\"],\n",
    "                [\"mh_career\",\"mhi_badresponse_work\"],\n",
    "                [\"mh_career\",\"observations_otherindividual_less_likely_reveal\"],\n",
    "                [\"mh_diagnosed_medprof\",\"sought_treatment\"],\n",
    "                [\"mhi_treated_inferencework\",\"mhi_NOTtreated_inferencework\"]\n",
    "            ]\n",
    "\n",
    "for x, y in li_test_pairs:\n",
    "\n",
    "    input = pd.crosstab(df_work[x], df_work[y], margins = False) \n",
    "\n",
    "    try:\n",
    "        stat, p, dof, expected = stats.chi2_contingency(input)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p <= alpha:\n",
    "        print(x + \" & \" + y + \" are Dependent. p value =\" + str(p))\n",
    "    else:\n",
    "        print(x + \" & \" + y + \" are Independent. p value =\" + str(p))\n",
    "\n",
    "#drop columns that are dependent\n",
    "li_drop_fields = [\"emp_disc_mhissue_negcons\", \"emp_disc_mhdisorder_coworkers\", \"emp_disc_mhdisorder_supervisor\", \"emp_observed_negcons\", \"prevemp_ph_disc_negcons\", \"prevemp_disc_mhissues_coworkers\", \"prevemp_disc_mhissues_supervisor\", \"prevemp_negcons\", \"mh_jobinterview\", \"mh_coworkers_perspective_neg\", \"mh_sharewfriends\", \"mhi_badresponse_work\", \"observations_otherindividual_less_likely_reveal\", \"mhdisorder_what_diagnosed\", \"sought_treatment\", \"mhi_NOTtreated_inferencework\", \"country_live\", \"usstate_live\", \"usstate_work\"]\n",
    "\n",
    "for f in li_drop_fields:\n",
    "    df_work.drop([f], axis=1, inplace=True)\n",
    "    print (f + \" deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning age column\n",
    "\n",
    "#print range of age column\n",
    "print(\"range of age column\")\n",
    "print(df_work['age'].min())\n",
    "print(df_work['age'].max())\n",
    "\n",
    "#detect outliers in age column\n",
    "sns.boxplot(x=df_work['age'])\n",
    "plt.show()\n",
    "\n",
    "#count number of outliers, excluding nan values\n",
    "print(\"number of outliers in age column\")\n",
    "print(\"over 90 years:\" + str(df_work.notna().loc[df_work['age'] > 90, 'age'].count()))\n",
    "print(\"unter 15 years:\" + str(df_work.notna().loc[df_work['age'] < 15, 'age'].count()))\n",
    "\n",
    "#delete these outliers\n",
    "df_work.drop(df_work[df_work['age'] > 90].index, inplace=True)\n",
    "df_work.drop(df_work[df_work['age'] < 15].index, inplace=True)\n",
    "\n",
    "df_work[\"age_cat\"] = np.where(df_work[\"age\"] > 64, \"Older than 64\", np.where(df_work[\"age\"] > 55, \"55-64\", np.where(df_work[\"age\"] > 25, \"54-25\", \"0-24\")))\n",
    "df_work.drop([\"age\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning gender column\n",
    "df_work[\"gender\"] = df_work[\"gender\"].str.lower()\n",
    "df_work[\"gender\"] = df_work[\"gender\"].str.strip()\n",
    "\n",
    "li_g_male = [\"cisdude\", \"cis male\",\"m\",\"man\",\"maile\", \"Make\", \"Mal\", \"Cis Man\",\"cis man\", \"man\", \"gender is male\", \"Male\", \"male\", \"ostensibly male, unsure what that really means\", \"male.\", \"M\", \"Malr\", \"malr\", \"Cis Male\", \"m\", \"mail\",\"male (cis)\", \"msle\", \"Mail\", \"male \", \"dude\", \"i'm a man why didn't you make this a drop down question. you should of asked sex? and i would of answered yes please. seriously how much text can this take?\"]\n",
    "li_g_female = [\"fem\", \"cis female\", \"cis-female/femme\", \"i identify as female.\", \"F\", \"Woman\", \"female (props for making this a freeform field, though)\", \"female assigned at birth\", \"female\", \"woman\", \"femail\", \"Female\", \"Femake\", \"Female (cis)\", \"cis-woman\", \"cisgender female\", \"female/woman\", \"f\", \"female-bodied; no feelings about gender\", \"fm\", \" female\", \"cis female\"]\n",
    "li_g_diverse = [\"non-binary\", \"agender\", \"human\", \"genderqueer\", \"nonbinary\", \"m|\", \"fluid\", \"male/genderqueer\", \"mtf\", \"unicorn\", \"male (trans, ftm)\", \"genderflux demi-girl\", \"afab\", \"queer\", \"enby\", \"genderqueer woman\", \"genderfluid\", \"none of your business\", \"sex is male\", \"nb masculine\", \"other\", \"male 9:1 female, roughly\", \"androgynous\", \"female or multi-gender femme\", \"other/transfeminine\", \"genderfluid (born female)\", \"transitioned, m2f\", \"bigender\", \"transgender woman\"]\n",
    "\n",
    "df_work[\"gender\"] = df_work[\"gender\"].replace(li_g_male, 'male')\n",
    "df_work[\"gender\"] = df_work[\"gender\"].replace(li_g_female, 'female')\n",
    "df_work[\"gender\"] = df_work[\"gender\"].replace(li_g_diverse, 'diverse')\n",
    "df_work[\"gender\"].fillna(\"diverse\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count unique values in each value to identify columns with high variety \n",
    "li_uniques = []\n",
    "\n",
    "for col in df_work.columns:\n",
    "    li_uniques.append([col, df_work[col].nunique()])\n",
    "\n",
    "df_uniques = pd.DataFrame(li_uniques, columns=[\"Col\",\"NUnique\"])\n",
    "\n",
    "print(df_uniques[(df_uniques[\"NUnique\"] > df_uniques[\"NUnique\"].quantile(0.95))][\"Col\"].to_list())\n",
    "\n",
    "#drop columns with high variety\n",
    "df_work.drop(df_uniques[(df_uniques[\"NUnique\"] > df_uniques[\"NUnique\"].quantile(0.95))][\"Col\"].to_list(), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning mhdisorder_what_diagnosed column\n",
    "df_work[\"medprof_what_diagnosed\"].fillna(\"No diagnosis\", inplace=True)\n",
    "\n",
    "df_work[\"medprof_what_diagnosed\"] = df_work[\"medprof_what_diagnosed\"].str.lower()\n",
    "df_work[\"medprof_what_diagnosed\"] = df_work[\"medprof_what_diagnosed\"].str.strip()\n",
    "\n",
    "li_f10 = [\"substance use disorder\",\"addictive disorder\"]\n",
    "li_f20 = [\"schizotypal personality disorder\", \"psychotic disorder (schizophrenia, schizoaffective, etc)\",\"schizotypal personality disorder 'autism spectrum disorder\", \"schizotypal personality disorder 'autism spectrum disorder'\", \"suicidal ideation\"]\n",
    "li_f30 = [\"depression\", \"seasonal affective disorder\", \"seasonal affective disorder 'burn out\", \"mood disorder (depression, bipolar disorder, etc)\"]\n",
    "li_f40 = [\"burn out\", \"obsessive-compulsive disorder\", \"post-traumatic stress disorder\", \"posttraumatic stress disourder\", \"stress response syndromes\", \"anxiety disorder (generalized, social, phobia, etc)\", \"dissociative disorder\"]\n",
    "li_f50 = [\"eating disorder (anorexia, bulimia, etc)\"]\n",
    "li_f60 = [\"gender dysphoria\", \"intimate disorder\", \"personality disorder (borderline, antisocial, paranoid, etc)\", \"gender identity disorder\"]\n",
    "li_f80 = ['\"autism (asperger\\'s)\",', \"autism (asperger's)\", \"asperger\", \"aspergers\", \"asperger syndrome\", \"attention deficit disorder (but not the hyperactive version)\", \"autism\", 'autism - while not a \"mental illness\", still greatly affects how i handle anxiety', \"autism spectrum disorder\", \"pdd-nos\", \"pdd-nos (see above)\"]\n",
    "li_f90 = [\"mcd (when it was diagnosed, the ultra-mega \\\"disorder\\\" adhd didn\\'t exist yet)\", \"attention deficit disorder\", \"attention deficit hyperactivity disorder\", \"add (w/o hyperactivity)\"]\n",
    "\n",
    "#replace and one hot encode\n",
    "df_diag_long = df_work[\"medprof_what_diagnosed\"].str.split(\"|\").explode().replace(li_f10, \"F10\").replace(li_f20, \"F20\").replace(li_f30, \"F30\").replace(li_f40, \"F40\").replace(li_f50, \"F50\").replace(li_f60, \"F60\").replace(li_f80, \"F80\").replace(li_f90, \"F90\").to_frame()\n",
    "df_work = pd.concat([df_work, pd.get_dummies(df_diag_long['medprof_what_diagnosed'],prefix='diag', prefix_sep='_')], axis=1)\n",
    "df_work.drop([\"medprof_what_diagnosed\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up work_position column\n",
    "df_work[\"work_position\"] = df_work[\"work_position\"].str.lower()\n",
    "df_work[\"work_position\"] = df_work[\"work_position\"].str.strip()\n",
    "df_work[\"work_position\"].fillna(\"other\", inplace=True)\n",
    "\n",
    "# Define dictionary to map original values to new values\n",
    "wp_dict = {'other': 'other', 'one-person shop': 'sole_proprietorship', 'hr': 'business_role', 'sales': 'business_role', 'support': 'business_role', 'back-end developer': 'developer', 'front-end developer': 'developer', 'executive leadership': 'leadership_role', 'supervisor/team lead': 'leadership_role', 'designer': 'non_dev_tech_role', 'dev evangelist/advocate': 'non_dev_tech_role', 'devops/sysadmin': 'non_dev_tech_role'}\n",
    "\n",
    "# Map the values in the \"work_position\" column and one-hot encode\n",
    "df_work[\"work_position\"] = df_work[\"work_position\"].map(wp_dict).str.split(\"|\").explode()\n",
    "df_work = pd.concat([df_work, pd.get_dummies(df_work['work_position'], prefix=\"wp\", prefix_sep=\"_\")], axis=1)\n",
    "df_work.drop([\"work_position\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up mh_diagnosed_medprof column\n",
    "df_work[\"mh_diagnosed_medprof\"] = df_work[\"mh_diagnosed_medprof\"].str.replace(\"Yes\", \"1\").replace(\"No\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower and strip all text in all columns\n",
    "for col in df_work.columns:\n",
    "    if df_work[col].dtype == \"object\":\n",
    "        df_work[col] = df_work[col].str.lower()\n",
    "        df_work[col] = df_work[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "df_emp = df_work.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean emp-dataframe\n",
    " \n",
    "#drop columns with 100% nan values\n",
    "li_nan = []\n",
    "for col in df_emp.columns:\n",
    "    if df_emp[col].isna().sum() == df_emp.shape[0]:\n",
    "        li_nan.append(col)\n",
    "df_emp.drop(li_nan, axis=1, inplace=True)\n",
    "\n",
    "# fill nan values, selecting an appropriate value for each column\n",
    "df_emp.isna().sum()\n",
    "df_emp[\"emp_know_options\"].fillna(\"i am not sure\", inplace=True)\n",
    "df_emp[\"prevemp_benefits\"].fillna(\"i don't know\", inplace=True)\n",
    "df_emp[\"prevemp_know_options\"].fillna(\"n/a (not currently aware)\", inplace=True)\n",
    "df_emp[\"prevemp_discussed\"].fillna(\"i don't know\", inplace=True)\n",
    "df_emp[\"prevemp_ressources\"].fillna(df_emp[\"prevemp_ressources\"].mode()[0], inplace=True)\n",
    "df_emp[\"prevemp_anonymity\"].fillna(\"i don't know\", inplace=True)\n",
    "df_emp[\"prevemp_mh_disc_negcons\"].fillna(\"i don't know\", inplace=True)\n",
    "df_emp[\"prevemp_mh_ph_serious\"].fillna(\"i don't know\", inplace=True)\n",
    "\n",
    "df_emp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in emp-dataframe, set nominal columns to category type and set categories\n",
    "df_emp[\"emp_benefits\"] = df_emp[\"emp_benefits\"].astype(\"category\")\n",
    "df_emp[\"emp_benefits\"].cat.set_categories([\"yes\", \"i don't know\", \"no\", \"not eligible for coverage / n/a\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_know_options\"] = df_emp[\"emp_know_options\"].astype(\"category\")\n",
    "df_emp[\"emp_know_options\"].cat.set_categories([\"yes\", \"no\", \"i am not sure\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_discussed\"] = df_emp[\"emp_discussed\"].astype(\"category\")\n",
    "df_emp[\"emp_discussed\"].cat.set_categories([\"yes\", \"no\", \"i don't know\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_ressources\"] = df_emp[\"emp_ressources\"].astype(\"category\")\n",
    "df_emp[\"emp_ressources\"].cat.set_categories([\"yes\", \"no\", \"i don't know\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_anonymity\"] = df_emp[\"emp_anonymity\"].astype(\"category\")\n",
    "df_emp[\"emp_anonymity\"].cat.set_categories([\"yes\", \"no\", \"i don't know\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_disc_mhdisorder_negcons\"] = df_emp[\"emp_disc_mhdisorder_negcons\"].astype(\"category\")\n",
    "df_emp[\"emp_disc_mhdisorder_negcons\"].cat.set_categories([\"yes\", \"no\", \"maybe\"], inplace=True)\n",
    "\n",
    "df_emp[\"emp_mh_ph_serious\"] = df_emp[\"emp_mh_ph_serious\"].astype(\"category\")\n",
    "df_emp[\"emp_mh_ph_serious\"].cat.set_categories([\"yes\", \"no\", \"i don't know\"], inplace=True)\n",
    "\n",
    "df_emp[\"ph_jobinterview\"] = df_emp[\"ph_jobinterview\"].astype(\"category\")\n",
    "df_emp[\"ph_jobinterview\"].cat.set_categories([\"yes\", \"no\", \"maybe\"], inplace=True)\n",
    "\n",
    "df_emp[\"family_history\"] = df_emp[\"family_history\"].astype(\"category\")\n",
    "df_emp[\"family_history\"].cat.set_categories([\"yes\", \"no\", \"i don't know\"], inplace=True)\n",
    "\n",
    "df_emp[\"mhdisorder_past\"] = df_emp[\"mhdisorder_past\"].astype(\"category\")\n",
    "df_emp[\"mhdisorder_past\"].cat.set_categories([\"yes\", \"no\", \"maybe\"], inplace=True)\n",
    "\n",
    "df_emp[\"mhdisorder_now\"] = df_emp[\"mhdisorder_now\"].astype(\"category\")\n",
    "df_emp[\"mhdisorder_now\"].cat.set_categories([\"yes\", \"no\", \"maybe\"], inplace=True)\n",
    "\n",
    "df_emp[\"gender\"] = df_emp[\"gender\"].astype(\"category\")\n",
    "df_emp[\"gender\"].cat.set_categories([\"male\", \"female\", \"diverse\"], inplace=True)\n",
    "\n",
    "df_emp[\"country_work\"] = df_emp[\"country_work\"].astype(\"category\")\n",
    "\n",
    "\n",
    "#in emp-dataframe, set ordinal columns to category type and set categories\n",
    "df_emp[\"num_employees\"] = df_emp[\"num_employees\"].astype(CategoricalDtype(categories=[\"1-5\",\"6-25\",\"26-100\",\"100-500\",\"500-1000\", \"more than 1000\"], ordered=True))\n",
    "\n",
    "df_emp[\"emp_medicalleave\"] = df_emp[\"emp_medicalleave\"].astype(CategoricalDtype(categories=[\"very easy\",\"somewhat easy\",\"neither easy nor difficult\",\"somewhat difficult\",\"very difficult\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_benefits\"] = df_emp[\"prevemp_benefits\"].astype(CategoricalDtype(categories=[\"yes, they all did\",\"some did\",\"no, none did\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_know_options\"] = df_emp[\"prevemp_know_options\"].astype(CategoricalDtype(categories=[\"yes, i was aware of all of them\",\"i was aware of some\",\"no, i only became aware later\",\"n/a (not currently aware)\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_discussed\"] = df_emp[\"prevemp_discussed\"].astype(CategoricalDtype(categories=[\"yes, they all did\",\"some did\",\"none did\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_ressources\"] = df_emp[\"prevemp_ressources\"].astype(CategoricalDtype(categories=[\"yes, they all did\",\"some did\",\"none did\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_anonymity\"] = df_emp[\"prevemp_anonymity\"].astype(CategoricalDtype(categories=[\"yes, always\",\"sometimes\",\"no\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_mh_disc_negcons\"] = df_emp[\"prevemp_mh_disc_negcons\"].astype(CategoricalDtype(categories=[\"yes, all of them\",\"some of them\",\"none of them\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"prevemp_mh_ph_serious\"] = df_emp[\"prevemp_mh_ph_serious\"].astype(CategoricalDtype(categories=[\"yes, they all did\",\"some did\",\"none did\",\"i don't know\"], ordered=True))\n",
    "\n",
    "df_emp[\"mh_career\"] = df_emp[\"mh_career\"].astype(CategoricalDtype(categories=[\"yes, it has\",\"yes, i think it would\",\"maybe\",\"no, i don't think it would\",\"no, it has not\"], ordered=True))\n",
    "\n",
    "df_emp[\"mhi_treated_inferencework\"] = df_emp[\"mhi_treated_inferencework\"].astype(CategoricalDtype(categories=[\"often\",\"sometimes\",\"never\",\"rarely\",\"not applicable to me\"], ordered=True))\n",
    "\n",
    "df_emp[\"remotework\"] = df_emp[\"remotework\"].astype(CategoricalDtype(categories=[\"always\",\"sometimes\",\"never\"], ordered=True))\n",
    "\n",
    "df_emp[\"age_cat\"] = df_emp[\"age_cat\"].astype(CategoricalDtype(categories=[\"0-24\",\"54-25\",\"55-64\",\"older than 64\"], ordered=True))\n",
    "\n",
    "\n",
    "#set mh_diagnosed_medprof to int64\n",
    "df_emp[\"mh_diagnosed_medprof\"] = df_emp[\"mh_diagnosed_medprof\"].astype(\"int64\")\n",
    "\n",
    "#df_emp dtypes\n",
    "print(df_emp.dtypes)\n",
    "print(df_emp.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After the data is cleaned, we will now start encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encoders = {}\n",
    "li_ordered = []\n",
    "li_not_ordered = []\n",
    "\n",
    "#encode ordinal columns\n",
    "for col in df_emp.columns:\n",
    "    if df_emp[col].dtype.name == \"category\":\n",
    "        if df_emp[col].cat.ordered:\n",
    "            print(col + \" ordered\")\n",
    "            li_ordered.append(col)\n",
    "            dict_encoders[col] = OrdinalEncoder()\n",
    "            df_emp[col] = dict_encoders[col].fit_transform(df_emp[[col]])\n",
    "        else:\n",
    "            print(col + \" not ordered\")\n",
    "            li_not_ordered.append(col)\n",
    "            dict_encoders[col] = OrdinalEncoder()\n",
    "            df_emp[col] = dict_encoders[col].fit_transform(df_emp[[col]])\n",
    "\n",
    "#set all columns to int64\n",
    "df_emp = df_emp.astype(\"int64\")\n",
    "df_emp.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**now, start clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate PCA on df_emp data\n",
    "pca = PCA()\n",
    "pca.fit(df_emp)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(1,45), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.savefig(\"PCA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct PCA on df_emp data\n",
    "pca = PCA(n_components=3, random_state=0)\n",
    "pca.fit(df_emp)\n",
    "pca_data_emp = pca.transform(df_emp)\n",
    "df_pca_emp = pd.DataFrame(pca_data_emp, columns=[\"pca1\", \"pca2\", \"pca3\"])\n",
    "print(df_pca_emp.head())\n",
    "\n",
    "#plot pca data in 3d\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter3D(df_pca_emp[\"pca1\"], df_pca_emp[\"pca2\"], df_pca_emp[\"pca3\"])\n",
    "ax.set_xlabel(\"pca1\")\n",
    "ax.set_ylabel(\"pca2\")\n",
    "ax.set_zlabel(\"pca3\")\n",
    "plt.savefig(\"PCA_3d.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores for different number of clusters\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init=\"k-means++\", random_state=0)\n",
    "    kmeans.fit(df_emp)\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_scores.append(silhouette_score(df_emp, labels, metric='euclidean'))\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(df_emp, labels))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(2, 11), silhouette_scores, label=\"Silhouette score\")\n",
    "plt.plot(range(2, 11), davies_bouldin_scores, label=\"Davies-Bouldin score\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#show best number of clusters\n",
    "print(silhouette_scores)\n",
    "print(davies_bouldin_scores)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "for i in [2, 3, 4, 5]:\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=0)\n",
    "    q, mod = divmod(i, 2)\n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df_emp)\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init=\"k-means++\", random_state=0)\n",
    "    kmeans.fit(df_emp)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(1, 11), wcss, marker=\"o\", linestyle=\"--\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores for different number of clusters using pca data\n",
    "silhouette_scores = []\n",
    "davies_bouldin_scores = []\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init=\"k-means++\", random_state=0)\n",
    "    kmeans.fit(df_pca_emp)\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_scores.append(silhouette_score(df_pca_emp, labels, metric='euclidean'))\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(df_pca_emp, labels))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(2, 11), silhouette_scores, label=\"Silhouette score\")\n",
    "plt.plot(range(2, 11), davies_bouldin_scores, label=\"Davies-Bouldin score\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#show best number of clusters\n",
    "print(silhouette_scores)\n",
    "print(davies_bouldin_scores)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "for i in [2, 3, 4, 5]:\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=0)\n",
    "    q, mod = divmod(i, 2)\n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df_pca_emp)      # Fit the data to the visualizer\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init=\"k-means++\", random_state=0)\n",
    "    kmeans.fit(df_pca_emp)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(1, 11), wcss, marker=\"o\", linestyle=\"--\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster data using kmeans, using optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=2, init=\"k-means++\", random_state=0)\n",
    "kmeans.fit(pca_data_emp)\n",
    "emp_labels = kmeans.labels_\n",
    "print(emp_labels)\n",
    "\n",
    "#silhouette score\n",
    "print(silhouette_score(df_pca_emp, emp_labels, metric='euclidean'))\n",
    "\n",
    "#put results into a dataframe\n",
    "df_emp_C = pd.concat([df_emp.reset_index(drop=True), df_pca_emp.reset_index(drop=True)], axis=1)\n",
    "df_emp_C.columns.values[-3:] = [\"pca1\", \"pca2\", \"pca3\"]\n",
    "df_emp_C['Cluster'] = emp_labels\n",
    "df_emp_C['Cluster'].replace({0:'Cluster 1', 1:'Cluster 2'}, inplace=True)\n",
    "df_emp_C.head()\n",
    "\n",
    "#drop trained models to save space\n",
    "del pca\n",
    "del kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try agglomerative clustering on pca data\n",
    "agg = AgglomerativeClustering(n_clusters=2)\n",
    "labels = agg.fit_predict(df_pca_emp)\n",
    "\n",
    "#silhouette score\n",
    "print(silhouette_score(df_pca_emp, labels, metric='euclidean'))\n",
    "\n",
    "#put results into a dataframe\n",
    "df_emp_CAGG = pd.concat([df_emp.reset_index(drop=True), df_pca_emp.reset_index(drop=True)], axis=1)\n",
    "df_emp_CAGG.columns.values[-3:] = [\"pca1\", \"pca2\", \"pca3\"]\n",
    "df_emp_CAGG['Cluster'] = labels\n",
    "df_emp_CAGG['Cluster'].replace({0:'Cluster 1', 1:'Cluster 2'}, inplace=True)\n",
    "\n",
    "#drop trained models to save space\n",
    "del agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try gaussian mixture model on pca data\n",
    "gmm = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "gmm.fit(df_pca_emp)\n",
    "labels = gmm.predict(df_pca_emp)\n",
    "\n",
    "#silhouette score\n",
    "print(silhouette_score(df_pca_emp, labels, metric='euclidean'))\n",
    "\n",
    "#put results into a dataframe\n",
    "df_emp_CGMM = pd.concat([df_emp.reset_index(drop=True), df_pca_emp.reset_index(drop=True)], axis=1)\n",
    "df_emp_CGMM.columns.values[-3:] = [\"pca1\", \"pca2\", \"pca3\"]\n",
    "df_emp_CGMM['Cluster'] = labels\n",
    "df_emp_CGMM['Cluster'].replace({0:'Cluster 1', 1:'Cluster 2'}, inplace=True)\n",
    "\n",
    "#drop trained models to save space\n",
    "del gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize df_emp_CGMM, df_emp_CAGG, df_emp_C in one plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,10))\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", data=df_emp_C, hue=\"Cluster\", hue_order=[\"Cluster 1\", \"Cluster 2\"], palette=[\"red\", \"green\"], ax=ax[0])\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", data=df_emp_CAGG, hue=\"Cluster\",hue_order=[\"Cluster 1\", \"Cluster 2\"], palette=[\"red\", \"green\"], ax=ax[1])\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", data=df_emp_CGMM, hue=\"Cluster\",hue_order=[\"Cluster 1\", \"Cluster 2\"], palette=[\"red\", \"green\"], ax=ax[2])\n",
    "plt.savefig(\"plots/cluster_comparison.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**start interpreting the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare cluster sizes\n",
    "print(df_emp_C['Cluster'].value_counts())\n",
    "\n",
    "#pie chart of cluster sizes\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "df_emp_C['Cluster'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax)\n",
    "plt.savefig('Plots/emp_cluster_pie.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepreate clusters\n",
    "df_emp_C1 = df_emp_C[df_emp_C['Cluster'] == 'Cluster 1'].drop(columns=['Cluster', 'pca1', 'pca2', 'pca3'])\n",
    "df_emp_C2 = df_emp_C[df_emp_C['Cluster'] == 'Cluster 2'].drop(columns=['Cluster', 'pca1', 'pca2', 'pca3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polar=df_emp_C.groupby(\"Cluster\").mean().reset_index()\n",
    "df_polar=pd.melt(df_polar,id_vars=[\"Cluster\"])\n",
    "fig4 = px.line_polar(df_polar, r=\"value\", theta=\"variable\", color=\"Cluster\", line_close=True,height=600,width=1000)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C1, value counts for each row\n",
    "df_emp_C1.apply(pd.Series.value_counts).fillna(0)\n",
    "df_emp_C1.apply(pd.Series.value_counts).fillna(0).T.apply(lambda x: x/x.sum(), axis=1)\n",
    "\n",
    "#plot value counts\n",
    "df_emp_C1.apply(pd.Series.value_counts).fillna(0).T.apply(lambda x: x/x.sum(), axis=1).plot(kind='barh', stacked=True, figsize=(20,10))\n",
    "plt.savefig('Plots/emp_cluster1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2, value counts for each row\n",
    "df_emp_C2.apply(pd.Series.value_counts).fillna(0)\n",
    "df_emp_C2.apply(pd.Series.value_counts).fillna(0).T.apply(lambda x: x/x.sum(), axis=1)\n",
    "\n",
    "#plot value counts\n",
    "df_emp_C2.apply(pd.Series.value_counts).fillna(0).T.apply(lambda x: x/x.sum(), axis=1).plot(kind='barh', stacked=True, figsize=(20,10))\n",
    "plt.savefig('Plots/emp_cluster2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_emp_C value counts for each row grouped by cluster\n",
    "df_emp_C_comp = df_emp_C.drop(columns=['pca1', 'pca2', 'pca3']).groupby('Cluster').apply(lambda x: x.apply(pd.Series.value_counts).fillna(0).T).drop(columns=['Cluster 1', 'Cluster 2']).apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).reset_index()\n",
    "df_emp_C_comp.rename(columns={'level_1':'variable'}, inplace=True)\n",
    "df_emp_C_comp = df_emp_C_comp.sort_values(by=['variable'])\n",
    "df_emp_C_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each variable, plot value counts for each row in bar chart horizontally stacked\n",
    "for var in df_emp_C_comp['variable'].unique():\n",
    "    df_emp_C_comp[df_emp_C_comp['variable'] == var].drop(columns=['variable']).set_index('Cluster').plot(kind='barh', stacked=True, figsize=(20,10))\n",
    "    plt.title(var)\n",
    "    plt.savefig('Plots/emp_' + var + '.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start asking questions on the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode categorical variables\n",
    "\n",
    "for d in dict_encoders:\n",
    "    df_emp[d] = dict_encoders[d].inverse_transform(df_emp[[d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage 'mhdisorder_now' in 'wp_business_role', 'wp_developer', 'wp_leadership_role', 'wp_non_dev_tech_role', 'wp_other', 'wp_sole_proprietorship'\n",
    "print(\"Current mental health issue in Business Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_business_role')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Business Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_business_role')[['mhdisorder_past']].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "\n",
    "print(\"Current mental health issue in Developer Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_developer')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Developer Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_developer')['mhdisorder_past'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "\n",
    "print(\"Current mental health issue in Leadership Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_leadership_role')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Leadership Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_leadership_role')['mhdisorder_past'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "\n",
    "print(\"Current mental health issue in Non-Dev Tech Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_non_dev_tech_role')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Non-Dev Tech Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_non_dev_tech_role')['mhdisorder_past'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "\n",
    "print(\"Current mental health issue in Other Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_other')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Other Roles\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_other')['mhdisorder_past'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "\n",
    "print(\"Current mental health issue in Sole Proprietorship\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_sole_proprietorship')['mhdisorder_now'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n",
    "print(\"Past mental health issue in Sole Proprietorship\")\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0].groupby('wp_sole_proprietorship')['mhdisorder_past'].value_counts().unstack().apply(lambda x: x/x.sum()*100, axis=1).round(2).fillna(0).astype(str) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of persons with current and past mental health disorder only in the tech companies.\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0][\"mhdisorder_now\"].value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")\n",
    "\n",
    "print(df_emp[df_emp[\"tech_comp\"] == 1.0][\"mhdisorder_past\"].value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of persons with current and past mental health disorder only in the tech companies by gender\n",
    "df_tech = df_emp[df_emp[\"tech_comp\"] == 1.0]\n",
    "print(df_tech[[\"mhdisorder_now\", \"gender\"]].groupby(by=\"gender\").value_counts(normalize=True).mul(100).round(2))\n",
    "print(df_tech[[\"mhdisorder_past\", \"gender\"]].groupby(by=\"gender\").value_counts(normalize=True).mul(100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of 'diag_F10', 'diag_F20', 'diag_F30', 'diag_F40', 'diag_F50', 'diag_F60', 'diag_F80', 'diag_F90', 'diag_no diagnosis' in tech companies by gender\n",
    "\n",
    "for diag in ['diag_F10', 'diag_F20', 'diag_F30', 'diag_F40', 'diag_F50', 'diag_F60', 'diag_F80', 'diag_F90', 'diag_no diagnosis']:\n",
    "    print(df_emp[[diag,'tech_comp','gender']][(df_emp[diag] == 1) & (df_emp['tech_comp'] == 1)].drop('tech_comp', axis=1).groupby(by='gender').count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supervised learning, target label mhdisorder_now\n",
    "\n",
    "#fetch new dataframe\n",
    "df_tech = df_emp[df_emp[\"tech_comp\"] == 1.0]\n",
    "\n",
    "#ordinal encoding\n",
    "for col in df_tech.columns:\n",
    "    df_tech[col] = OrdinalEncoder().fit_transform(df_tech[[col]])\n",
    "\n",
    "#drop irrelevant columns\n",
    "df_tech = df_tech.drop(['diag_F10', 'diag_F20', 'diag_F30', 'diag_F40', 'diag_F50', 'diag_F60', 'diag_F80', 'diag_F90', 'diag_no diagnosis', 'tech_comp', 'prev_emp', 'mh_diagnosed_medprof', ], axis=1)\n",
    "\n",
    "#creating the feature and target variables\n",
    "y = df_tech['mhdisorder_now']\n",
    "x = df_tech.drop(['mhdisorder_now', 'mhdisorder_past'], axis=1)\n",
    "\n",
    "#splitting the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#fitting the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#predicting the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "#evaluating the model\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "#feature importance\n",
    "feature_importance = abs(model.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "featfig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "feats = x.columns\n",
    "feats = feats[sorted_idx]\n",
    "feature_importance = feature_importance[sorted_idx]\n",
    "plt.barh(pos, feature_importance, align='center')\n",
    "plt.yticks(pos, feats)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.savefig('Plots/feature_importance.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#make dataframe of feature importance\n",
    "df_feat_imp = pd.DataFrame({'feature': x.columns, 'importance': feature_importance})\n",
    "df_feat_imp = df_feat_imp.sort_values(by='importance', ascending=False)\n",
    "print(df_feat_imp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87df95c5240a3c97c5f4c6a0dcfaece0546cd5ebe00ec0e7b370d3fb8aa34b9a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
